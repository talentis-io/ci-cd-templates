name: Run AI Analysis

on:
  workflow_call:
    inputs:
      repo_name:
        required: true
        type: string
      branch_name:
        required: true
        type: string
      sonar_project_key:
        required: false
        type: string
        default: ""
    outputs:
      score:
        description: "AI analysis score"
        value: ${{ jobs.ai-analysis.outputs.score }}
      analysis_html:
        description: "AI analysis HTML report"
        value: ${{ jobs.ai-analysis.outputs.analysis_html }}
      percentage_advancement:
        description: "Percentage of advancement based on test document"
        value: ${{ jobs.ai-analysis.outputs.percentage_advancement }}

jobs:
  ai-analysis:
    runs-on: ubuntu-latest
    outputs:
      score: ${{ steps.ai-analysis.outputs.score }}
      analysis_html: ${{ steps.ai-analysis.outputs.analysis_html }}
      percentage_advancement: ${{ steps.ai-analysis.outputs.percentage_advancement }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/${{ inputs.repo_name }}
          ref: ${{ inputs.branch_name }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Get SonarCloud metrics
        id: sonar-metrics
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_PROJECT_KEY: ${{ inputs.sonar_project_key != '' && inputs.sonar_project_key || format('talentis-io_{0}', inputs.repo_name) }}
        run: |
          sleep 10
          RESPONSE=$(curl -s -u $SONAR_TOKEN: \
            "https://sonarcloud.io/api/measures/component?component=$SONAR_PROJECT_KEY&metricKeys=bugs,vulnerabilities,security_hotspots,code_smells,coverage,duplicated_lines_density,ncloc,sqale_index,reliability_rating,security_rating,sqale_rating")

          echo "sonar_response<<EOF" >> $GITHUB_OUTPUT
          echo "$RESPONSE" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          BUGS=$(echo "$RESPONSE" | jq -r '.component.measures[] | select(.metric == "bugs") | .value // "0"')
          VULNERABILITIES=$(echo "$RESPONSE" | jq -r '.component.measures[] | select(.metric == "vulnerabilities") | .value // "0"')
          CODE_SMELLS=$(echo "$RESPONSE" | jq -r '.component.measures[] | select(.metric == "code_smells") | .value // "0"')
          COVERAGE=$(echo "$RESPONSE" | jq -r '.component.measures[] | select(.metric == "coverage") | .value // "0"')
          LINES_OF_CODE=$(echo "$RESPONSE" | jq -r '.component.measures[] | select(.metric == "ncloc") | .value // "0"')

          echo "bugs=$BUGS" >> $GITHUB_OUTPUT
          echo "vulnerabilities=$VULNERABILITIES" >> $GITHUB_OUTPUT
          echo "code_smells=$CODE_SMELLS" >> $GITHUB_OUTPUT
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          echo "lines_of_code=$LINES_OF_CODE" >> $GITHUB_OUTPUT

          - name: Prepare project context
          id: project-context
          run: |
            echo "Extracting code context..."
        
            CODE_SNIPPETS=$(find src -type f \( -name "*.js" -o -name "*.jsx" -o -name "*.ts" -o -name "*.tsx" \) \
              -not -path "*/node_modules/*" | head -3 | xargs -I{} sh -c 'echo "===== {} ====="; head -n 40 "{}"; echo ""')
        
            PACKAGE_CONTENT=""
            if [ -f "package.json" ]; then
              PACKAGE_CONTENT=$(cat package.json | head -n 100)
            fi
        
            README_CONTENT=""
            if [ -f "README.md" ]; then
              README_CONTENT=$(head -n 50 README.md)
            fi
        
            # ðŸ§  Compress the collected code for smaller prompt size
            COMPRESSED_CODE=$(echo "$CODE_SNIPPETS" | gzip | base64)
        
            echo "compressed_code<<EOF" >> $GITHUB_OUTPUT
            echo "$COMPRESSED_CODE" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
        
            echo "package_content<<EOF" >> $GITHUB_OUTPUT
            echo "$PACKAGE_CONTENT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
        
            echo "readme_content<<EOF" >> $GITHUB_OUTPUT
            echo "$README_CONTENT" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT        

      - name: Get test attachment document
        id: test-attachment
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          REPO_NAME: ${{ inputs.repo_name }}
        run: |
          if [ -z "$WEBHOOK_URL" ]; then
            echo "WARNING: WEBHOOK_URL not set, skipping test attachment retrieval"
            echo "document_text=" >> $GITHUB_OUTPUT
            exit 0
          fi

          BASE_URL=$(echo "$WEBHOOK_URL" | sed 's|/webhook/sonar$||' | sed 's|/webhook$||' | sed 's|/$||')
          RESPONSE=$(curl -s -w "\n%{http_code}" -X GET "${BASE_URL}/webhook/test-attachment/${REPO_NAME}")
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          RESPONSE_BODY=$(echo "$RESPONSE" | sed '$d')

          if [ "$HTTP_CODE" = "200" ]; then
            TEXT_CONTENT=$(echo "$RESPONSE_BODY" | jq -r '.textContent // ""')
            if [ -n "$TEXT_CONTENT" ] && [ "$TEXT_CONTENT" != "null" ]; then
              echo "document_text<<EOF" >> $GITHUB_OUTPUT
              echo "$TEXT_CONTENT" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            else
              echo "document_text=" >> $GITHUB_OUTPUT
            fi
          else
            echo "document_text=" >> $GITHUB_OUTPUT
          fi

      - name: Generate AI Analysis
        id: ai-analysis
        env:
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
          OLLAMA_BASE_URL: ${{ secrets.OLLAMA_BASE_URL || 'https://ollama.com' }}
          OLLAMA_MODEL: ${{ secrets.OLLAMA_MODEL || 'gpt-oss:120b' }}
        run: |
          DOCUMENT_TEXT="${{ steps.test-attachment.outputs.document_text }}"

          if [ -n "$DOCUMENT_TEXT" ] && [ "$DOCUMENT_TEXT" != "" ]; then
            DOCUMENT_SECTION="DOCUMENT DE TEST DU CANDIDAT:
          Ce document contient les instructions et le contexte du test Ã  rÃ©aliser.
          
          $DOCUMENT_TEXT
          
          BASÃ‰ SUR CE DOCUMENT, tu dois:
          1. Ã‰valuer le degrÃ© d'avancement (0-100%)
          2. Ã‰valuer la qualitÃ© technique (SonarCloud + code)
          3. Produire un score global (0-100)"
          else
            DOCUMENT_SECTION="DOCUMENT DE TEST: Non disponible"
          fi

          cat > /tmp/prompt.txt << PROMPT_EOF
          Tu es un expert en analyse de code et qualitÃ© logicielle. Analyse le projet suivant en te basant sur les mÃ©triques SonarCloud, le document de test du candidat et le code fourni.

          INFORMATIONS DU PROJET:
          - Nom du projet: ${{ inputs.repo_name }}
          - Branche: ${{ inputs.branch_name }}

          $DOCUMENT_SECTION

          MÃ‰TRIQUES SONARCLOUD:
          - Bugs: ${{ steps.sonar-metrics.outputs.bugs }}
          - VulnÃ©rabilitÃ©s: ${{ steps.sonar-metrics.outputs.vulnerabilities }}
          - Code smells: ${{ steps.sonar-metrics.outputs.code_smells }}
          - Couverture de code: ${{ steps.sonar-metrics.outputs.coverage }}%
          - Lignes de code: ${{ steps.sonar-metrics.outputs.lines_of_code }}

          EXTRAITS DE CODE SOURCE:
          ${{ steps.project-context.outputs.code_snippets }}

          INFORMATIONS SUPPLÃ‰MENTAIRES:
          - package.json:
          ${{ steps.project-context.outputs.package_content }}

          - README.md (dÃ©but):
          ${{ steps.project-context.outputs.readme_content }}

          RÃ©ponds UNIQUEMENT au format JSON suivant:
          {
            "score": [0-100],
            "percentage_advancement": [0-100],
            "analysis_html": "<div class='space-y-1'>...</div>"
          }

          PROMPT_EOF

          PROMPT=$(cat /tmp/prompt.txt)
          ESCAPED_PROMPT=$(echo "$PROMPT" | jq -R -s .)

          cat > /tmp/payload.json << JSON_EOF
          {
            "model": "$OLLAMA_MODEL",
            "messages": [
              {"role": "user", "content": $ESCAPED_PROMPT}
            ],
            "temperature": 0.7,
            "max_tokens": 4000
          }
          JSON_EOF

          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST "$OLLAMA_BASE_URL/v1/chat/completions" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $OLLAMA_API_KEY" \
            -d @/tmp/payload.json)

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          RESPONSE_BODY=$(echo "$RESPONSE" | sed '$d')

          if [ "$HTTP_CODE" != "200" ]; then
            echo "ERROR: API returned HTTP $HTTP_CODE"
            echo "$RESPONSE_BODY"
            exit 1
          fi

          AI_RESPONSE=$(echo "$RESPONSE_BODY" | jq -r '.choices[0].message.content // empty')
          SCORE=$(echo "$AI_RESPONSE" | jq -r '.score // "50"')
          PERCENTAGE_ADVANCEMENT=$(echo "$AI_RESPONSE" | jq -r '.percentage_advancement // "0"')
          echo "$AI_RESPONSE" | jq -r '.analysis_html // "N/A"' > /tmp/analysis_html.txt
          ANALYSIS_HTML=$(cat /tmp/analysis_html.txt)

          {
            echo "score=$SCORE"
            echo "percentage_advancement=$PERCENTAGE_ADVANCEMENT"
            echo "analysis_html<<EOF"
            echo "$ANALYSIS_HTML"
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Display AI Analysis Results
        run: |
          echo "=== RÃ‰SULTATS DE L'ANALYSE IA ==="
          echo "Score (qualitÃ© technique): ${{ steps.ai-analysis.outputs.score }}/100"
          echo "Pourcentage d'avancement: ${{ steps.ai-analysis.outputs.percentage_advancement }}%"
          echo ""
          echo "=== RAPPORT HTML COMPLET ==="
          echo "${{ steps.ai-analysis.outputs.analysis_html }}"
          echo "=== FIN DU RAPPORT ==="
